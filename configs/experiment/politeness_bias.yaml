# Phase 2
experiment:
  name: "politeness_bias"
  bias_type: "politeness"
  lambda_values: [0.0, 0.1, 0.3, 0.5, 1.0]
  seeds: [42, 123, 456]

training:
  num_train_epochs: 1
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 4
  learning_rate: 1.0e-6
  warmup_steps: 10
  num_generations: 8
  max_completion_length: 512
  temperature: 0.7
  beta: 0.04
  logging_steps: 10
  save_steps: 100
  log_completions: true
  bf16: true
